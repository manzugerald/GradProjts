{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf650114-987c-40db-8864-f8ae55c9f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pmdarima import auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6c4df66-f33b-471a-9ea3-dc9cee7cf2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annual_Mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>27.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>27.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>27.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>27.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>27.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Annual_Mean\n",
       "Year             \n",
       "1901        27.34\n",
       "1902        27.16\n",
       "1903        27.12\n",
       "1904        27.09\n",
       "1905        27.06"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "data = pd.read_csv('data.csv')  # Ensure filename matches\n",
    "\n",
    "data.columns = ['Year', 'Annual_Mean', 'Smooth_5yr']  # Ensure proper column names\n",
    "data = data[['Year', 'Annual_Mean']]\n",
    "data.set_index('Year', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56767efb-9fce-40c2-a2a6-52161f7124a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "split_index = int(len(data) * 0.8)\n",
    "train, test = data.iloc[:split_index], data.iloc[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "583e4e7b-3a6b-4837-aabc-f6d27cd0ae50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annual_Mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>27.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>27.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>27.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>27.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>28.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Annual_Mean\n",
       "Year             \n",
       "1998        27.83\n",
       "1999        27.31\n",
       "2000        27.84\n",
       "2001        27.90\n",
       "2002        28.27"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3191a802-ada6-4a78-b204-6b566f7d759d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,1,2)(1,0,1)[10] intercept   : AIC=inf, Time=1.25 sec\n",
      " ARIMA(0,1,0)(0,0,0)[10] intercept   : AIC=67.564, Time=0.07 sec\n",
      " ARIMA(1,1,0)(1,0,0)[10] intercept   : AIC=59.681, Time=0.10 sec\n",
      " ARIMA(0,1,1)(0,0,1)[10] intercept   : AIC=44.863, Time=0.14 sec\n",
      " ARIMA(0,1,0)(0,0,0)[10]             : AIC=65.585, Time=0.03 sec\n",
      " ARIMA(0,1,1)(0,0,0)[10] intercept   : AIC=43.141, Time=0.07 sec\n",
      " ARIMA(0,1,1)(1,0,0)[10] intercept   : AIC=44.926, Time=0.13 sec\n",
      " ARIMA(0,1,1)(1,0,1)[10] intercept   : AIC=inf, Time=0.57 sec\n",
      " ARIMA(1,1,1)(0,0,0)[10] intercept   : AIC=45.013, Time=0.08 sec\n",
      " ARIMA(0,1,2)(0,0,0)[10] intercept   : AIC=44.793, Time=0.15 sec\n",
      " ARIMA(1,1,0)(0,0,0)[10] intercept   : AIC=57.684, Time=0.06 sec\n",
      " ARIMA(1,1,2)(0,0,0)[10] intercept   : AIC=40.762, Time=0.16 sec\n",
      " ARIMA(1,1,2)(1,0,0)[10] intercept   : AIC=42.668, Time=0.22 sec\n",
      " ARIMA(1,1,2)(0,0,1)[10] intercept   : AIC=42.638, Time=0.26 sec\n",
      " ARIMA(1,1,2)(1,0,1)[10] intercept   : AIC=44.386, Time=0.50 sec\n",
      " ARIMA(2,1,2)(0,0,0)[10] intercept   : AIC=41.222, Time=0.18 sec\n",
      " ARIMA(1,1,3)(0,0,0)[10] intercept   : AIC=39.561, Time=0.15 sec\n",
      " ARIMA(1,1,3)(1,0,0)[10] intercept   : AIC=40.643, Time=0.25 sec\n",
      " ARIMA(1,1,3)(0,0,1)[10] intercept   : AIC=40.511, Time=0.29 sec\n",
      " ARIMA(1,1,3)(1,0,1)[10] intercept   : AIC=39.920, Time=0.54 sec\n",
      " ARIMA(0,1,3)(0,0,0)[10] intercept   : AIC=37.779, Time=0.11 sec\n",
      " ARIMA(0,1,3)(1,0,0)[10] intercept   : AIC=38.891, Time=0.19 sec\n",
      " ARIMA(0,1,3)(0,0,1)[10] intercept   : AIC=38.770, Time=0.22 sec\n",
      " ARIMA(0,1,3)(1,0,1)[10] intercept   : AIC=inf, Time=0.50 sec\n",
      " ARIMA(0,1,4)(0,0,0)[10] intercept   : AIC=39.682, Time=0.15 sec\n",
      " ARIMA(1,1,4)(0,0,0)[10] intercept   : AIC=40.794, Time=0.37 sec\n",
      " ARIMA(0,1,3)(0,0,0)[10]             : AIC=35.867, Time=0.32 sec\n",
      " ARIMA(0,1,3)(1,0,0)[10]             : AIC=37.028, Time=0.16 sec\n",
      " ARIMA(0,1,3)(0,0,1)[10]             : AIC=36.917, Time=0.14 sec\n",
      " ARIMA(0,1,3)(1,0,1)[10]             : AIC=inf, Time=0.47 sec\n",
      " ARIMA(0,1,2)(0,0,0)[10]             : AIC=42.931, Time=0.05 sec\n",
      " ARIMA(1,1,3)(0,0,0)[10]             : AIC=37.657, Time=0.10 sec\n",
      " ARIMA(0,1,4)(0,0,0)[10]             : AIC=37.774, Time=0.10 sec\n",
      " ARIMA(1,1,2)(0,0,0)[10]             : AIC=38.901, Time=0.09 sec\n",
      " ARIMA(1,1,4)(0,0,0)[10]             : AIC=38.545, Time=0.29 sec\n",
      "\n",
      "Best model:  ARIMA(0,1,3)(0,0,0)[10]          \n",
      "Total fit time: 9.394 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manzu\\.conda\\envs\\twitter\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\manzu\\.conda\\envs\\twitter\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\manzu\\.conda\\envs\\twitter\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    }
   ],
   "source": [
    "# SARIMA Model using AutoARIMA\n",
    "auto_arima_model = auto_arima(train, seasonal=True, m=10, trace=True, suppress_warnings=True)\n",
    "best_order = auto_arima_model.order\n",
    "best_seasonal_order = auto_arima_model.seasonal_order\n",
    "\n",
    "sarima_model = SARIMAX(train, order=best_order, seasonal_order=best_seasonal_order)\n",
    "sarima_fit = sarima_model.fit()\n",
    "sarima_pred = sarima_fit.forecast(steps=len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c53e9c2a-4846-4343-88be-1f746590d28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manzu\\.conda\\envs\\twitter\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "test_scaled = scaler.transform(test)\n",
    "\n",
    "X_train, y_train = train_scaled[:-1], train_scaled[1:]\n",
    "X_test, y_test = test_scaled[:-1], test_scaled[1:]\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "    LSTM(50, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "lstm_model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "\n",
    "lstm_pred = lstm_model.predict(X_test)\n",
    "lstm_pred = scaler.inverse_transform(lstm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f85c8825-7101-49d7-b608-198b2806675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(np.array(train.index).reshape(-1,1), train['Annual_Mean'])\n",
    "rf_pred = rf_model.predict(np.array(test.index).reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d61e964d-2694-40b1-8d75-aa5ae5175791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARIMA -> MAE: 0.4177, RMSE: 0.5448, R²: -0.7254\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25, 24]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, R²: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m evaluate(test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnnual_Mean\u001b[39m\u001b[38;5;124m'\u001b[39m], sarima_pred, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSARIMA\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAnnual_Mean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLSTM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m evaluate(test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnnual_Mean\u001b[39m\u001b[38;5;124m'\u001b[39m], rf_pred, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(y_true, y_pred, model_name)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(y_true, y_pred, model_name):\n\u001b[1;32m----> 3\u001b[0m     mae \u001b[38;5;241m=\u001b[39m \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     rmse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_true, y_pred, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m     r2 \u001b[38;5;241m=\u001b[39m r2_score(y_true, y_pred)\n",
      "File \u001b[1;32m~\\.conda\\envs\\twitter\\lib\\site-packages\\sklearn\\metrics\\_regression.py:196\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_absolute_error\u001b[39m(\n\u001b[0;32m    142\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    143\u001b[0m ):\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m    0.85...\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    200\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\twitter\\lib\\site-packages\\sklearn\\metrics\\_regression.py:100\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    102\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\.conda\\envs\\twitter\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [25, 24]"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "def evaluate(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f'{model_name} -> MAE: {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}')\n",
    "\n",
    "evaluate(test['Annual_Mean'], sarima_pred, 'SARIMA')\n",
    "evaluate(test['Annual_Mean'], lstm_pred, 'LSTM')\n",
    "evaluate(test['Annual_Mean'], rf_pred, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54278a93-829b-420f-9c9f-1e23ff3e6738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
